{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb364ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from pack import unpack_tensortrain\n",
    "from multilevel2 import MultilevelSurrogate\n",
    "from darcy1d import Darcy1D\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a96c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_surrogates(L, main_dir, args):\n",
    "    base_dir = main_dir / \"base_tensors\"\n",
    "    refine_dir = main_dir / \"refinement_tensors\"\n",
    "\n",
    "    num_samplesizes = len(args[\"samplesizes\"])\n",
    "\n",
    "    surrogates = []\n",
    "    work_estimates = []\n",
    "    for start_idx in range(L - 1, num_samplesizes):\n",
    "        u = MultilevelSurrogate(d=args[\"d\"], L=L)\n",
    "\n",
    "        N = args[\"samplesizes\"][start_idx]\n",
    "        l = args[\"max_discr_level\"] - L + 1\n",
    "\n",
    "        with np.load(base_dir / f\"N{N}.npz\") as data:\n",
    "            # print(data.files)\n",
    "            ttcomponents_packed = data[f\"l{l}\"]\n",
    "        ttcomponents = unpack_tensortrain(ttcomponents_packed)\n",
    "\n",
    "        u.set_layer(0, ttcomponents)\n",
    "        work = N * 2**l\n",
    "\n",
    "        for layer_idx in range(1, L):\n",
    "            N = args[\"samplesizes\"][start_idx - layer_idx]\n",
    "            l += 1\n",
    "            work += N + (2**l + 2 ** (l - 1))\n",
    "\n",
    "            with np.load(refine_dir / f\"N{N}.npz\") as data:\n",
    "                # print(data.files)\n",
    "                ttcomponents_packed = data[f\"l{l}\"]\n",
    "            ttcomponents = unpack_tensortrain(ttcomponents_packed)\n",
    "            u.set_layer(layer_idx, ttcomponents)\n",
    "\n",
    "        surrogates.append(u)\n",
    "        work_estimates.append(work)\n",
    "    return surrogates, work_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75666f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m test_discr_level \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m14\u001b[39m\n\u001b[1;32m      3\u001b[0m test_discr_degree \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 5\u001b[0m testpoints \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, (testsize, \u001b[43margs\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m      6\u001b[0m testvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(testsize)\n\u001b[1;32m      7\u001b[0m testvalues_coarse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(testsize)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "testsize = 1_000\n",
    "test_discr_level = 14\n",
    "test_discr_degree = 2\n",
    "testpoints = np.random.uniform(-1, 1, (testsize, d)\n",
    "testvalues = np.zeros(testsize)\n",
    "testvalues_coarse = np.zeros(testsize)\n",
    "testproblem = Darcy1D(test_discr_level, args[\"d\"], test_discr_degree)\n",
    "testproblem_coarse = Darcy1D(10, args[\"d\"], 1)\n",
    "\n",
    "for i in tqdm(range(testsize)):\n",
    "    testvalues[i] = testproblem.get_integrated_solution(testpoints[i])\n",
    "    testvalues_coarse[i] = testproblem_coarse.get_integrated_solution(testpoints[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60992762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_experiment(main_dir, L_max, testpoints, testvalues, testvalues_coarse):\n",
    "    main_dir = Path(main_dir)\n",
    "    with open(main_dir / \"experiment_args.json\", \"r\") as f:\n",
    "        args = dict(json.load(f))\n",
    "\n",
    "    print(args)\n",
    "\n",
    "    plt.figure()\n",
    "    als_name = args[\"als\"].upper()\n",
    "    max_discr_level = args[\"max_discr_level\"]\n",
    "    d = args[\"d\"]\n",
    "    weights = r\"$w_{\\nu} = \\prod_j\\sqrt{2\\nu_j + 1}$\"\n",
    "    if args[\"radius_option\"] == 2:\n",
    "        weights = r\"$w_{\\nu} = \\prod_j \\sqrt{2\\nu_j + 1}\\, 1.01\\, \\nu_j^{3/4}$\"\n",
    "    plt.title(f\"{als_name}, dim={d}, finest mesh size: 2^{max_discr_level}, {weights}\")\n",
    "\n",
    "    fem_error = np.sqrt(np.mean((testvalues - testvalues_coarse) ** 2))\n",
    "    plt.axhline(y=fem_error, color=\"gray\", linestyle=\"--\", label=\"FEM error\")\n",
    "\n",
    "    for L in range(1, L_max + 1):\n",
    "        surrogates, work_estimates = compute_surrogates(\n",
    "            L, main_dir, args\n",
    "        )  # work_estimates: shape (k,)\n",
    "        work_estimates = np.asarray(work_estimates)\n",
    "\n",
    "        preds = np.array([u(testpoints) for u in surrogates])  # shape (k, n_test)\n",
    "        rmse = np.sqrt(\n",
    "            np.mean((preds - testvalues[None, :]) ** 2, axis=1)\n",
    "        )  # shape (k,)\n",
    "\n",
    "        # optional: sort by work so the lines look nice\n",
    "        order = np.argsort(work_estimates)\n",
    "        w_sorted = work_estimates[order]\n",
    "        rmse_sorted = rmse[order]\n",
    "\n",
    "        if L == 1:\n",
    "            als_rmse = np.sqrt(\n",
    "                np.mean((preds - testvalues_coarse[None, :]) ** 2, axis=1)\n",
    "            )\n",
    "            als_rmse_sorted = als_rmse[order]\n",
    "            plt.loglog(w_sorted, als_rmse_sorted, \"--\", label=f\"{als_name} error\")\n",
    "\n",
    "        plt.loglog(w_sorted, rmse_sorted, \"o-\", label=f\"L = {L}\")\n",
    "\n",
    "    plt.xlabel(\"work\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.grid(True, which=\"both\", ls=\":\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46146973",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_experiment(\"experiments0/SALS1\", 5, testpoints, testvalues, testvalues_coarse)\n",
    "plot_experiment(\"experiments0/SALS2\", 5, testpoints, testvalues, testvalues_coarse)\n",
    "plot_experiment(\"experiments0/SSALS1\", 5, testpoints, testvalues, testvalues_coarse)\n",
    "plot_experiment(\"experiments0/SSALS2\", 5, testpoints, testvalues, testvalues_coarse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sals-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
